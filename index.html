<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>MediaPipe Hand Tracking Full Screen</title>

  <!-- MediaPipe scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

  <style>
    html, body {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background: black;
      width: 100%;
      height: 100%;
    }
    video {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover; /* Fill screen without squishing */
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }
  </style>
</head>
<body>
  <video id="input_video" autoplay playsinline muted></video>
  <canvas id="output_canvas"></canvas>

  <script>
    const videoElement = document.getElementById("input_video");
    const canvasElement = document.getElementById("output_canvas");
    const canvasCtx = canvasElement.getContext("2d");

    // Resize canvas to match video
    function resizeCanvas() {
      canvasElement.width = videoElement.videoWidth || window.innerWidth;
      canvasElement.height = videoElement.videoHeight || window.innerHeight;
    }

    videoElement.addEventListener('loadedmetadata', resizeCanvas);
    window.addEventListener("resize", resizeCanvas);

    // Initialize MediaPipe Hands
    const hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });

    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.5,
    });

    hands.onResults((results) => {
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

      if (results.image) {
        canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
      }

      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0];

        drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, { color: "#00FF00", lineWidth: 3 });
        drawLandmarks(canvasCtx, landmarks, { color: "#FF0000", lineWidth: 2 });

        if (window.ReactNativeWebView) {
          window.ReactNativeWebView.postMessage(JSON.stringify({ landmarks }));
        } else {
          console.log("Hand detected:", landmarks);
        }
      }
      canvasCtx.restore();
    });

    // Start camera
    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
        videoElement.srcObject = stream;

        const camera = new Camera(videoElement, {
          onFrame: async () => { await hands.send({ image: videoElement }); },
          width: 1280,
          height: 720,
        });

        camera.start();
      } catch (err) {
        console.error("Camera failed:", err);
        alert("Camera failed to start. Make sure permissions are allowed.");
      }
    }

    startCamera();
  </script>
</body>
</html>
